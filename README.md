LocalLlama (3.2)

Bash script to interface with a local llama 3.2 (or other) model using llama.cpp via llama-cli. 
Use -i or -interactive to enable chat mode (llama-cli interactive mode).

Setup:
- download a compatible .gguf model and set the MODEL_PATH
- set LLAMA_EXECUTABLE to the path to llama-cli
